{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk6d9yOhuSkr"
   },
   "source": [
    "## 掛載雲端硬碟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NTpFfZGuVSx"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEETyGg0uZnb"
   },
   "source": [
    "##更改檔案所在路徑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wum2GQmwucfZ"
   },
   "outputs": [],
   "source": [
    "# Change to your own folder !!!\n",
    "%cd /content/drive/MyDrive/Colab\\ Notebooks/EAI_Lab4_2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9NTZ1VEtbV7"
   },
   "source": [
    "## 載入函式庫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCvF-fM0tfsq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from models import vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X_r4dtMuwbh"
   },
   "source": [
    "##超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2NkY0LyuyQh"
   },
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'\n",
    "TEST_BATCH_SIZE = 1000\n",
    "CUDA = True\n",
    "PRUNE_PERCENT = 0.9 # Change your prune ratio!\n",
    "# WEIGHT_PATH = '/content/drive/MyDrive/Colab Notebooks/model_best.pth'\n",
    "# PRUNE_PATH = '/content/drive/MyDrive/Colab Notebooks/model_prune.pth'\n",
    "\n",
    "WEIGHT_PATH = 'weights/train2.pth'\n",
    "PRUNE_PATH = 'weights/train2-prune50.pth'\n",
    "# PRUNE_PATH = 'weights/train1-prune90.pth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7z4dkhJwB4Z"
   },
   "source": [
    "##載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpIqnhfKwEcJ"
   },
   "outputs": [],
   "source": [
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "\n",
    "model = vgg()\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "if WEIGHT_PATH:\n",
    "    if os.path.isfile(WEIGHT_PATH):\n",
    "        checkpoint = torch.load(WEIGHT_PATH)\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n",
    "\n",
    "    else:\n",
    "        print(\"NO CHECKPOINT FOUND\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0nUbcNtA_SA"
   },
   "source": [
    "##測試函數(觀察模型精確度)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md44Lc-WBIaf"
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])),\n",
    "        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "          if CUDA:\n",
    "              data, target = data.cuda(), target.cuda()\n",
    "          data, target = Variable(data), Variable(target)\n",
    "          output = model(data)\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srauYOD-1vSp"
   },
   "source": [
    "## 進行剪枝\n",
    "#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n",
    "#### 利用PRUNE_RATIO中取得閥值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgtUBaDw1uuR"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        total += m.weight.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "y, i = torch.sort(bn)\n",
    "\n",
    "\n",
    "threshold_index = int(total * PRUNE_PERCENT)\n",
    "threshold = y[threshold_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sy0JNTN-h3B"
   },
   "source": [
    "##建立CONFIG，之後建立剪枝後網路時需要用到此CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBklaqUZHnvp"
   },
   "outputs": [],
   "source": [
    "pruned = 0\n",
    "cfg = []  #用來建立剪枝網路的CONFIG\n",
    "cfg_mask = [] #用來幫助剪枝的遮罩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66vDWd5BMmph"
   },
   "source": [
    "## 根據Batch Normalization Layer資訊建立CONFIG\n",
    "#### 1. 複製Batch Normalization Layer的weight(也就是scale factor)\n",
    "#### 2. 建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n",
    "#### 3. 大於threshold的index的值加總後，會是剪枝後Layer對應的輸出channel\n",
    "#### 4. 最後得到要建立剪枝模型的CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10ilGgoZ1SR1"
   },
   "outputs": [],
   "source": [
    "for k, m in enumerate(model.modules()):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        weight_copy = m.weight.data.clone()\n",
    "        mask = weight_copy.abs().gt(threshold).float().cuda()\n",
    "\n",
    "        # 注意: 需自行設計處理剩下channel數為0的情況 (e.g. 至少保留3個channel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        cfg.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.clone())\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "    elif isinstance(m, nn.MaxPool2d):\n",
    "        cfg.append('M')\n",
    "\n",
    "pruned_ratio = pruned/total\n",
    "\n",
    "print(f'PRUNE RATIO={pruned_ratio}')\n",
    "print('PREPROCESSING SUCCESSFUL!')\n",
    "\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ha2BuBl1ifM"
   },
   "source": [
    "###建立剪枝模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlWNdj2f1nWs"
   },
   "outputs": [],
   "source": [
    "newmodel = vgg(cfg=cfg)\n",
    "newmodel.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms9Usgkh1Vbe"
   },
   "source": [
    "###將原本的模型權重複製到剪枝的模型\n",
    "####1.決定該層的輸入與輸出Channel\n",
    "####2.根據不同層決定要複製什麼權重\n",
    "######Batch Normalization Layer\n",
    "1.   scale factor\n",
    "2.   bias\n",
    "3.   running mean\n",
    "4.   running variance\n",
    "\n",
    "######Convolutional Layer\n",
    "1.   weight\n",
    "2.   bias\n",
    "\n",
    "######Linear Layer\n",
    "1.   weight\n",
    "2.   bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQcKuMDee46V"
   },
   "outputs": [],
   "source": [
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3) #3為input channel(R,G,B)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "count = 0\n",
    "for [m0, m1] in zip(model.modules(), newmodel.modules()):\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "\n",
    "        # 處理剪枝後的權重\n",
    "        m0.weight.data.mul_(end_mask)\n",
    "        m0.bias.data.mul_(end_mask)\n",
    "\n",
    "        #### 找出遮罩中非零元素的index ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "\n",
    "\n",
    "        # 將原本模型的權重複製到剪枝模型的權重\n",
    "\n",
    "        #### 複製weight與bias ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "\n",
    "\n",
    "        #### 複製running mean跟running variance ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "\n",
    "\n",
    "\n",
    "        layer_id_in_cfg += 1\n",
    "        start_mask = end_mask.clone()\n",
    "\n",
    "        #最後一層連接層不做修改\n",
    "        if layer_id_in_cfg < len(cfg_mask):\n",
    "            end_mask = cfg_mask[layer_id_in_cfg]\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        # 將原本模型的捲積層權重複製到對應剪枝模型卷積層的權重\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "\n",
    "        w = m0.weight.data[:, idx0, :, :].clone()\n",
    "        w = w[idx1, :, :, :].clone()\n",
    "        m1.weight.data = w.clone()\n",
    "        #m1.bias.data = m0.bias.data[idx1].clone()\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        # 參考 https://pytorch.org/docs/stable/generated/torch.nn.Linear.html 來決定該如何複製Linear Layer參數\n",
    "\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "\n",
    "        #### 複製weight ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "\n",
    "\n",
    "\n",
    "        #### 複製bias ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFkMmFLo88mc"
   },
   "source": [
    "####儲存模型並印出結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuo3HXHt9Ar-"
   },
   "outputs": [],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n",
    "\n",
    "print(newmodel)\n",
    "model = newmodel\n",
    "test(newmodel)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
