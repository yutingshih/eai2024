{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 掛載雲端硬碟"],"metadata":{"id":"Lk6d9yOhuSkr"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3NTpFfZGuVSx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##更改檔案所在路徑\n"],"metadata":{"id":"VEETyGg0uZnb"}},{"cell_type":"code","source":["# Change to your own folder !!!\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/EAI_Lab4_2023"],"metadata":{"id":"Wum2GQmwucfZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 載入函式庫\n"],"metadata":{"id":"S9NTZ1VEtbV7"}},{"cell_type":"code","source":["import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","import numpy as np\n","\n","from models import vgg"],"metadata":{"id":"vCvF-fM0tfsq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##超參數設定"],"metadata":{"id":"_X_r4dtMuwbh"}},{"cell_type":"code","source":["DATASET = 'cifar10'\n","TEST_BATCH_SIZE = 1000\n","CUDA = True\n","PRUNE_PERCENT = 0.9 # Change your prune ratio!\n","WEIGHT_PATH = '/content/drive/MyDrive/Colab Notebooks/model_best.pth'\n","PRUNE_PATH = '/content/drive/MyDrive/Colab Notebooks/model_prune.pth'\n"],"metadata":{"id":"_2NkY0LyuyQh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##載入模型"],"metadata":{"id":"L7z4dkhJwB4Z"}},{"cell_type":"code","source":["CUDA = CUDA and torch.cuda.is_available()\n","\n","model = vgg()\n","if CUDA:\n","    model.cuda()\n","\n","if WEIGHT_PATH:\n","    if os.path.isfile(WEIGHT_PATH):\n","        checkpoint = torch.load(WEIGHT_PATH)\n","        best_prec1 = checkpoint['best_prec1']\n","        model.load_state_dict(checkpoint['state_dict'])\n","        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n","\n","    else:\n","        print(\"NO CHECKPOINT FOUND\")\n","\n","print(model)"],"metadata":{"id":"lpIqnhfKwEcJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##測試函數(觀察模型精確度)\n"],"metadata":{"id":"U0nUbcNtA_SA"}},{"cell_type":"code","source":["def test(model):\n","    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n","    test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])),\n","        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","      for data, target in test_loader:\n","          if CUDA:\n","              data, target = data.cuda(), target.cuda()\n","          data, target = Variable(data), Variable(target)\n","          output = model(data)\n","          pred = output.data.max(1, keepdim=True)[1]\n","          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n","        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n","    return correct / float(len(test_loader.dataset))"],"metadata":{"id":"Md44Lc-WBIaf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 進行剪枝\n","#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n","#### 利用PRUNE_RATIO中取得閥值"],"metadata":{"id":"srauYOD-1vSp"}},{"cell_type":"code","source":["total = 0\n","for m in model.modules():\n","    if isinstance(m, nn.BatchNorm2d):\n","        total += m.weight.data.shape[0]\n","\n","bn = torch.zeros(total)\n","index = 0\n","for m in model.modules():\n","    if isinstance(m, nn.BatchNorm2d):\n","        size = m.weight.data.shape[0]\n","        bn[index:(index+size)] = m.weight.data.abs().clone()\n","        index += size\n","\n","y, i = torch.sort(bn)\n","\n","\n","threshold_index = int(total * PRUNE_PERCENT)\n","threshold = y[threshold_index]\n"],"metadata":{"id":"xgtUBaDw1uuR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##建立CONFIG，之後建立剪枝後網路時需要用到此CONFIG"],"metadata":{"id":"1sy0JNTN-h3B"}},{"cell_type":"code","source":["pruned = 0\n","cfg = []  #用來建立剪枝網路的CONFIG\n","cfg_mask = [] #用來幫助剪枝的遮罩"],"metadata":{"id":"PBklaqUZHnvp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##根據Batch Normalization Layer資訊建立CONFIG\n","####1.複製Batch Normalization Layer的weight(也就是scale factor)\n","####2.建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n","####3.大於threshold的index的值加總後，會是剪枝後Layer對應的輸出channel\n","####4.最後得到要建立剪枝模型的CONFIG"],"metadata":{"id":"66vDWd5BMmph"}},{"cell_type":"code","source":["for k, m in enumerate(model.modules()):\n","    if isinstance(m, nn.BatchNorm2d):\n","        weight_copy = m.weight.data.clone()\n","        mask = weight_copy.abs().gt(threshold).float().cuda()\n","\n","        # 注意: 需自行設計處理剩下channel數為0的情況 (e.g. 至少保留3個channel)\n","\n","\n","\n","\n","\n","\n","\n","        pruned = pruned + mask.shape[0] - torch.sum(mask)\n","        cfg.append(int(torch.sum(mask)))\n","        cfg_mask.append(mask.clone())\n","        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n","            format(k, mask.shape[0], int(torch.sum(mask))))\n","    elif isinstance(m, nn.MaxPool2d):\n","        cfg.append('M')\n","\n","pruned_ratio = pruned/total\n","\n","print(f'PRUNE RATIO={pruned_ratio}')\n","print('PREPROCESSING SUCCESSFUL!')\n","\n","print(cfg)\n"],"metadata":{"id":"10ilGgoZ1SR1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###建立剪枝模型"],"metadata":{"id":"_ha2BuBl1ifM"}},{"cell_type":"code","source":["newmodel = vgg(cfg=cfg)\n","newmodel.cuda()"],"metadata":{"id":"SlWNdj2f1nWs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###將原本的模型權重複製到剪枝的模型\n","####1.決定該層的輸入與輸出Channel\n","####2.根據不同層決定要複製什麼權重\n","######Batch Normalization Layer\n","1.   scale factor\n","2.   bias\n","3.   running mean\n","4.   running variance\n","\n","######Convolutional Layer\n","1.   weight\n","2.   bias\n","\n","######Linear Layer\n","1.   weight\n","2.   bias\n","\n"],"metadata":{"id":"ms9Usgkh1Vbe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQcKuMDee46V"},"outputs":[],"source":["layer_id_in_cfg = 0\n","start_mask = torch.ones(3) #3為input channel(R,G,B)\n","end_mask = cfg_mask[layer_id_in_cfg]\n","count = 0\n","for [m0, m1] in zip(model.modules(), newmodel.modules()):\n","    if isinstance(m0, nn.BatchNorm2d):\n","\n","        # 處理剪枝後的權重\n","        m0.weight.data.mul_(end_mask)\n","        m0.bias.data.mul_(end_mask)\n","\n","        #### 找出遮罩中非零元素的index ####\n","        ################################################\n","        #          請填空          #\n","        ################################################\n","\n","\n","        # 將原本模型的權重複製到剪枝模型的權重\n","\n","        #### 複製weight與bias ####\n","        ################################################\n","        #          請填空          #\n","        ################################################\n","\n","\n","        #### 複製running mean跟running variance ####\n","        ################################################\n","        #          請填空          #\n","        ################################################\n","\n","\n","\n","        layer_id_in_cfg += 1\n","        start_mask = end_mask.clone()\n","\n","        #最後一層連接層不做修改\n","        if layer_id_in_cfg < len(cfg_mask):\n","            end_mask = cfg_mask[layer_id_in_cfg]\n","    elif isinstance(m0, nn.Conv2d):\n","        # 將原本模型的捲積層權重複製到對應剪枝模型卷積層的權重\n","        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n","        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n","\n","        w = m0.weight.data[:, idx0, :, :].clone()\n","        w = w[idx1, :, :, :].clone()\n","        m1.weight.data = w.clone()\n","        #m1.bias.data = m0.bias.data[idx1].clone()\n","    elif isinstance(m0, nn.Linear):\n","        # 參考 https://pytorch.org/docs/stable/generated/torch.nn.Linear.html 來決定該如何複製Linear Layer參數\n","\n","        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n","\n","        #### 複製weight ####\n","        ################################################\n","        #          請填空          #\n","        ################################################\n","\n","\n","\n","        #### 複製bias ####\n","        ################################################\n","        #          請填空          #\n","        ################################################\n","\n"]},{"cell_type":"markdown","source":["####儲存模型並印出結果\n"],"metadata":{"id":"AFkMmFLo88mc"}},{"cell_type":"code","source":["torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n","\n","print(newmodel)\n","model = newmodel\n","test(newmodel)"],"metadata":{"id":"cuo3HXHt9Ar-"},"execution_count":null,"outputs":[]}]}