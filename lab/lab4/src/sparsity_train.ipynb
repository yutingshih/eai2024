{"cells":[{"cell_type":"markdown","metadata":{"id":"U3at1mhslz9v"},"source":["##掛載雲端硬碟\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijtFdN9tl14V"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"q5bhyRZrl4X2"},"source":["##更改檔案所在路徑"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2RXiD5Bl6a2"},"outputs":[],"source":["# Change to your own folder !!!\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/EAI_Lab4_2023"]},{"cell_type":"markdown","metadata":{"id":"gSal5HL0lTHA"},"source":["## Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6v2iM_kglWj-"},"outputs":[],"source":["from __future__ import print_function\n","import os\n","import argparse\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","from models import vgg"]},{"cell_type":"markdown","metadata":{"id":"yFgiQGL6mq6W"},"source":["## 設定超參數(填空)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8FQ-IsUmqtP"},"outputs":[],"source":["SPARSITY_REGULARIZATION = True\n","#### 設定λ(balance factor) ####\n","################################################\n","#          請填空          #\n","################################################\n","LAMBDA =\n","\n","SEED = 1\n","TRAIN_BATCH_SIZE = 100\n","TEST_BATCH_SIZE = 1000\n","EPOCHS = 60\n","LEARNING_RATE = 0.1\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 1e-4\n","LOG_INTERVAL = 100\n","CUDA = True\n","\n","RESUME = False\n","START_EPOCH = 0\n","\n","WEIGHT_PATH = '/content/drive/MyDrive/Colab Notebooks/model_best.pth'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Sa1Tmnym3Pn"},"outputs":[],"source":["if(torch.cuda.is_available()):\n","    CUDA = True\n","    kwargs = {'num_workers': 1, 'pin_memory': True}\n","    torch.cuda.manual_seed(SEED)\n","else:\n","    CUDA = False\n","    kwargs = {}\n"]},{"cell_type":"markdown","metadata":{"id":"fylf4FTlm7QX"},"source":["##下載資料集\n"]},{"cell_type":"markdown","metadata":{"id":"erS9S_76nUsG"},"source":["這裡將訓練集做Augmentation(Pad, RandCrop, Random)，測試集不用做Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBW21uIHm_C-"},"outputs":[],"source":["#### 資料集 ####\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.Pad(4),\n","                       transforms.RandomCrop(32),\n","                       transforms.RandomHorizontalFlip(),\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                   ])),\n","    batch_size=TRAIN_BATCH_SIZE, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                   ])),\n","    batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)"]},{"cell_type":"markdown","metadata":{"id":"Is49FKBbuRj2"},"source":["## 定義模型與載入訓練好的權重"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUbUcHN4uQ89"},"outputs":[],"source":["model = vgg()\n","if CUDA:\n","    model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"ZC8ECoKHu7iF"},"source":["##設定Optimizer，這裡使用Stocastic Gradient Descent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQ-soeyWvGyM"},"outputs":[],"source":["optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"]},{"cell_type":"markdown","metadata":{"id":"txRrgb22vLD9"},"source":["##使用論文中稀疏化的方式更新參數(填空)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7ekcGWXvcXu"},"outputs":[],"source":["def updateBN():\n","  for m in model.modules():\n","      if isinstance(m, nn.BatchNorm2d):\n","          #### 完成Sparsity Regularization ####\n","          ################################################\n","          #          請填空          #\n","          ################################################\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PAD78g28ns_C"},"source":["## 載入預先定義好的模型與參數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKUUpjTan4Zq"},"outputs":[],"source":["if(RESUME):\n","  checkpoint = torch.load(WEIGHT_PATH)\n","  model.load_state_dict(checkpoint['state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  START_EPOCH = checkpoint['epoch']\n","  best_prec1 = checkpoint['best_prec1']\n","  print(f'RESUME MODEL @EPOCH={START_EPOCH}, BEST_PREC1={best_prec1}')"]},{"cell_type":"markdown","metadata":{"id":"gR2UTh0iwbEF"},"source":["## 定義訓練跟測試函數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQcKuMDee46V"},"outputs":[],"source":["#### 訓練函數 #####\n","\n","# 注意: 需自行撰寫儲存每個epoch之train acc的code，以便後續繪製train acc結果圖!\n","def train(epoch):\n","    model.train()\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        if CUDA:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data), Variable(target)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()\n","\n","        if SPARSITY_REGULARIZATION:\n","            updateBN()\n","        optimizer.step()\n","        if batch_idx % LOG_INTERVAL == 0:\n","            print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data.item()))\n","\n","\n","\n","#### 測試函數 ####\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","      for data, target in test_loader:\n","          if CUDA:\n","              data, target = data.cuda(), target.cuda()\n","          data, target = Variable(data), Variable(target)\n","          output = model(data)\n","          test_loss += F.cross_entropy(output, target, reduction='sum').data.item()\n","          pred = output.data.max(1, keepdim=True)[1]\n","          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","      test_loss /= len(test_loader.dataset)\n","      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n","          test_loss, correct, len(test_loader.dataset),\n","          100. * correct / len(test_loader.dataset)))\n","      return correct / float(len(test_loader.dataset))\n","\n","best_prec1 = 0.\n","for epoch in range(START_EPOCH, EPOCHS):\n","    # Learning Rate在0.5EPOCHS與0.75EPOCHS調整為原本1/10\n","    if epoch in [EPOCHS*0.5, EPOCHS*0.75]:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] *= 0.1\n","    train(epoch)\n","    prec1 = test()\n","\n","    # 儲存模型權重，方便做後續剪枝,後續訓練\n","    if(prec1 > best_prec1):\n","        torch.save({\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'best_prec1': best_prec1,\n","            'optimizer': optimizer.state_dict(),\n","        }, WEIGHT_PATH)\n","\n","    best_prec1 = max(prec1, best_prec1)\n"]},{"cell_type":"markdown","source":["##繪製Sparsity-Training結果圖"],"metadata":{"id":"pPoQuFgx3mD9"}},{"cell_type":"code","source":["#繪製 Sparsity-Training 結果圖\n"],"metadata":{"id":"x7O2cE4q52A-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 繪製scaling factor 分布圖"],"metadata":{"id":"nw_CWhNSC7wT"}},{"cell_type":"code","source":["#繪製 scaling factor 分布圖"],"metadata":{"id":"ohSv3VlZCyuM"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}